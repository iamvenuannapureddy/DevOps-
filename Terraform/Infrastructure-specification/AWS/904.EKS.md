<h1>EKS-Elastic Kubernetes Service</h1>

When creating an EKS (Elastic Kubernetes Service) cluster using Terraform, there are several key resources and configurations you need to define to ensure proper setup. These resources range from the EKS cluster itself to associated networking and security configurations like VPC, subnets, IAM roles, node groups, and more.

### Key Resource Specifications for EKS

1. **VPC and Networking**
2. **IAM Roles and Policies**
3. **EKS Cluster**
4. **Node Groups or Managed Node Groups**
5. **Security Groups**
6. **Autoscaling and Desired Capacity**
7. **Storage**
8. **Logging and Monitoring**
9. **Tags**

---

### 1. **VPC and Networking**
EKS needs to be deployed inside a VPC, with subnets, route tables, and an internet gateway for cluster communication and networking.

#### Key Resources:
- `aws_vpc`: VPC for the EKS cluster.
- `aws_subnet`: Subnets where the EKS cluster will run.
- `aws_internet_gateway`: To enable internet access for the EKS cluster.
- `aws_route_table` and `aws_route`: To define routing in the VPC.
- `aws_nat_gateway`: Optional, for private subnets to access the internet.
  
#### Example:
```hcl
resource "aws_vpc" "eks_vpc" {
  cidr_block = "10.0.0.0/16"
}

resource "aws_subnet" "eks_subnet" {
  count = 2
  vpc_id = aws_vpc.eks_vpc.id
  cidr_block = cidrsubnet(aws_vpc.eks_vpc.cidr_block, 8, count.index)
}

resource "aws_internet_gateway" "eks_igw" {
  vpc_id = aws_vpc.eks_vpc.id
}

resource "aws_route_table" "eks_route_table" {
  vpc_id = aws_vpc.eks_vpc.id
}

resource "aws_route" "eks_route" {
  route_table_id         = aws_route_table.eks_route_table.id
  destination_cidr_block = "0.0.0.0/0"
  gateway_id             = aws_internet_gateway.eks_igw.id
}
```

---

### 2. **IAM Roles and Policies**
EKS requires specific IAM roles for both the control plane and worker nodes to interact with AWS services securely.

#### Key Resources:
- `aws_iam_role`: IAM role for the EKS control plane and worker nodes.
- `aws_iam_policy`: IAM policies to attach to the roles.
- `aws_iam_role_policy_attachment`: Attach policies to the IAM roles.

#### Example:
```hcl
# IAM Role for EKS Cluster
resource "aws_iam_role" "eks_cluster_role" {
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "eks.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "eks_cluster_AmazonEKSClusterPolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
  role       = aws_iam_role.eks_cluster_role.name
}

# IAM Role for Worker Nodes
resource "aws_iam_role" "eks_worker_role" {
  assume_role_policy = <<EOF
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Action": "sts:AssumeRole",
      "Principal": {
        "Service": "ec2.amazonaws.com"
      },
      "Effect": "Allow",
      "Sid": ""
    }
  ]
}
EOF
}

resource "aws_iam_role_policy_attachment" "eks_worker_AmazonEKSWorkerNodePolicy" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
  role       = aws_iam_role.eks_worker_role.name
}

resource "aws_iam_role_policy_attachment" "eks_worker_AmazonEC2ContainerRegistryReadOnly" {
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
  role       = aws_iam_role.eks_worker_role.name
}
```

---

### 3. **EKS Cluster**
This is the main resource for defining the EKS cluster.

#### Key Resource:
- `aws_eks_cluster`: The EKS cluster resource.

#### Key Parameters:
- `name`: Name of the EKS cluster.
- `role_arn`: The ARN of the IAM role for the EKS control plane.
- `vpc_config`: The VPC configuration, including subnets and security groups.

#### Example:
```hcl
resource "aws_eks_cluster" "eks_cluster" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn

  vpc_config {
    subnet_ids = aws_subnet.eks_subnet[*].id
    security_group_ids = [aws_security_group.eks_cluster_sg.id]
  }

  tags = {
    Name = "EKS-Cluster"
  }
}
```

---

### 4. **Node Groups or Managed Node Groups**
Nodes are the EC2 instances that form the worker nodes of the EKS cluster. Terraform can create both unmanaged and managed node groups.

#### Key Resource:
- `aws_eks_node_group` (for managed node groups)
- `aws_launch_template` or `aws_autoscaling_group` (for unmanaged node groups)

#### Key Parameters:
- `node_role`: IAM role associated with the EC2 instances in the node group.
- `subnet_ids`: Subnets where the worker nodes are deployed.
- `scaling_config`: Configuration for the number of nodes.

#### Example (Managed Node Group):
```hcl
resource "aws_eks_node_group" "my_node_group" {
  cluster_name    = aws_eks_cluster.eks_cluster.name
  node_group_name = "my-node-group"
  node_role       = aws_iam_role.eks_worker_role.arn
  subnets         = aws_subnet.eks_subnet[*].id

  scaling_config {
    desired_size = 2
    max_size     = 3
    min_size     = 1
  }

  tags = {
    Name = "EKS-Node-Group"
  }
}
```

---

### 5. **Security Groups**
You need to define security groups to control access between the EKS control plane, worker nodes, and external services.

#### Key Resource:
- `aws_security_group`: Security groups for the cluster and worker nodes.

#### Example:
```hcl
resource "aws_security_group" "eks_cluster_sg" {
  vpc_id = aws_vpc.eks_vpc.id

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
}
```

---

### 6. **Autoscaling and Desired Capacity**
When setting up node groups, you can configure autoscaling parameters to define the minimum, maximum, and desired number of worker nodes in the cluster.

#### Example:
```hcl
resource "aws_eks_node_group" "my_node_group" {
  cluster_name    = aws_eks_cluster.eks_cluster.name
  node_group_name = "my-node-group"
  node_role       = aws_iam_role.eks_worker_role.arn
  subnets         = aws_subnet.eks_subnet[*].id

  scaling_config {
    desired_size = 3
    max_size     = 5
    min_size     = 1
  }
}
```

---

### 7. **Storage**
EKS may require storage for applications or services running on the cluster. This can be configured using EBS volumes or by integrating S3, depending on the Kubernetes workload requirements.

#### Example:
- **EBS storage classes**: Can be configured through Kubernetes manifests once the cluster is running.
- **S3 storage**: Can be accessed by applications running on the cluster.

---

### 8. **Logging and Monitoring**
AWS EKS integrates with CloudWatch for logging, which can be enabled to monitor the clusterâ€™s logs.

#### Key Resource:
- `enable_logging`: In `aws_eks_cluster` to enable control plane logging.

#### Example:
```hcl
resource "aws_eks_cluster" "eks_cluster" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn

  vpc_config {
    subnet_ids         = aws_subnet.eks_subnet[*].id
    security_group_ids = [aws_security_group.eks_cluster_sg.id]
  }

  enabled_cluster_log_types = ["api", "audit", "authenticator"]
}
```

---

### 9. **Tags**
Tags are used to organize and manage EKS resources. You can apply tags to almost all AWS resources, including clusters, node groups, and subnets.

#### Example:
```hcl
resource "aws_eks_cluster" "eks_cluster" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn

  vpc_config {
    subnet_ids = aws_subnet.eks_subnet[*].id
  }

  tags = {
    Environment = "Production"
    Owner       = "DevOps"
  }
}
```

---

### Summary
To create an EKS cluster using Terraform, you need to set up a VPC and networking, IAM roles, the E

KS cluster itself, and worker node groups. You'll also want to configure security groups, autoscaling, logging, and tagging. By specifying these key resources, you can successfully deploy and manage an EKS cluster with Terraform.

If you need more specific examples or details, feel free to ask!
